{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#model1 = nn.Sequential(OrderedDict([\n",
    "#    ('hidden', nn.\n",
    "#]))\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 2)),\n",
    "    ('output', nn.Linear(2, 1))\n",
    "]))\n",
    "\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(2, 5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(5, 3)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('fc3', nn.Linear(3, 1)),\n",
    "    ('relu3', nn.ReLU())\n",
    "]))\n",
    "\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(2, 5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(5, 3)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('fc3', nn.Linear(3, 1)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "# the database contains 0 and 1 because we must add two bits\n",
    "# 3 layers: the input and output layers and one hidden layer\n",
    "# the activation function is the sigmoid function\n",
    "# the loss function is\n",
    "\n",
    "# for MODEL 1:\n",
    "# input layer has 2 neurons, hidden layer has 2 neurons and output layer has 1 neuron\n",
    "\n",
    "# for MODEL 2:\n",
    "# input layer has 2 neurons, hidden layer has 4 neurons and output layer has 1 neuron\n",
    "\n",
    "# for MODEL 3:\n",
    "# input layer has 2 neurons, hidden layer has 8 neurons and output layer has 1 neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (output): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (fc1): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (relu3): ReLU()\n",
      ")\n",
      "Sequential(\n",
      "  (fc1): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#data_in = torch.tensor( ...\n",
    "#contains all the possible combinations of bits(0, 1)\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# data_target = torch.tensor( ...\n",
    "# contains all the possible results of adding 2 bits\n",
    "data_target = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# criterion = \n",
    "# optimizer =\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.1) # calculates gradients with learning rate 0.1\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.1)\n",
    "optimizer3 = torch.optim.SGD(model3.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1\n",
      "Epoch [100/1000], Loss: 0.6945\n",
      "Epoch [200/1000], Loss: 0.6937\n",
      "Epoch [300/1000], Loss: 0.6933\n",
      "Epoch [400/1000], Loss: 0.6932\n",
      "Epoch [500/1000], Loss: 0.6932\n",
      "Epoch [600/1000], Loss: 0.6932\n",
      "Epoch [700/1000], Loss: 0.6932\n",
      "Epoch [800/1000], Loss: 0.6931\n",
      "Epoch [900/1000], Loss: 0.6931\n",
      "Epoch [1000/1000], Loss: 0.6931\n",
      "MODEL 2\n",
      "Epoch [100/1000], Loss: 0.6932\n",
      "Epoch [200/1000], Loss: 0.6931\n",
      "Epoch [300/1000], Loss: 0.6931\n",
      "Epoch [400/1000], Loss: 0.6931\n",
      "Epoch [500/1000], Loss: 0.6931\n",
      "Epoch [600/1000], Loss: 0.6931\n",
      "Epoch [700/1000], Loss: 0.6931\n",
      "Epoch [800/1000], Loss: 0.6931\n",
      "Epoch [900/1000], Loss: 0.6931\n",
      "Epoch [1000/1000], Loss: 0.6931\n",
      "MODEL 3\n",
      "Epoch [100/1000], Loss: 0.7270\n",
      "Epoch [200/1000], Loss: 0.7178\n",
      "Epoch [300/1000], Loss: 0.7112\n",
      "Epoch [400/1000], Loss: 0.7066\n",
      "Epoch [500/1000], Loss: 0.7034\n",
      "Epoch [600/1000], Loss: 0.7012\n",
      "Epoch [700/1000], Loss: 0.6996\n",
      "Epoch [800/1000], Loss: 0.6984\n",
      "Epoch [900/1000], Loss: 0.6975\n",
      "Epoch [1000/1000], Loss: 0.6968\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Train the model\n",
    "\n",
    "# train the model 1 for 1000 epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "print('MODEL 1')\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    output = model1(data_in)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, data_target)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# train the model 2 for 1000 epochs\n",
    "\n",
    "print('MODEL 2')\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    output = model2(data_in)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, data_target)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer2.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer2.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# train the model 3 for 1000 epochs\n",
    "\n",
    "print('MODEL 3')\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    output = model3(data_in)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, data_target)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer3.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer3.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1's predictions:\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Model 2's predictions:\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Model 3's predictions:\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# visualize the results\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for MODEL 1:\n",
    "\n",
    "output = model1(data_in)\n",
    "\n",
    "# Convert the output probabilities to binary predictions\n",
    "predictions = (output >= 0.5).float()\n",
    "\n",
    "# Print the model's predictions\n",
    "print(\"Model 1's predictions:\")\n",
    "print(predictions)\n",
    "\n",
    "# for MODEL 2:\n",
    "\n",
    "output = model2(data_in)\n",
    "\n",
    "# Convert the output probabilities to binary predictions\n",
    "predictions = (output >= 0.5).float()\n",
    "\n",
    "# Print the model's predictions\n",
    "print(\"Model 2's predictions:\")\n",
    "print(predictions)\n",
    "\n",
    "# for MODEL 3:\n",
    "\n",
    "output = model3(data_in)\n",
    "\n",
    "# Convert the output probabilities to binary predictions\n",
    "predictions = (output >= 0.5).float()\n",
    "\n",
    "# Print the model's predictions\n",
    "print(\"Model 3's predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# print model weights\n",
    "\n",
    "accuracies = []\n",
    "models = [model1, model2, model3]\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data_in)\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        accuracy = (predicted == data_target).float().mean()\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy.item() * 100))\n",
    "\n",
    "# Select the best-performing model\n",
    "best_model = models[accuracies.index(max(accuracies))]\n",
    "\n",
    "print('Model ' + str(accuracies.index(max(accuracies)) + 1) + ' is the best!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
